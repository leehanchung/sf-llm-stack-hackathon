{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"LkNZ6hp6K8l6"},"source":["# LangChain QA Scrap Pad"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"data":{"text/plain":["True"]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["import os\n","from typing import List\n","import pandas as pd\n","import redis\n","from langchain.vectorstores.redis import Redis\n","from langchain.llms import OpenAI\n","from langchain.prompts import PromptTemplate\n","from langchain.chains import RetrievalQA\n","from langchain.embeddings import OpenAIEmbeddings\n","from dotenv import load_dotenv\n","\n","load_dotenv()"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["CACHE_TYPE = os.getenv(\"CACHE_TYPE\")\n","REDIS_URL = os.getenv(\"REDIS_URL\")\n","OPENAI_COMPLETIONS_ENGINE = os.getenv(\"OPENAI_COMPLETIONS_ENGINE\")\n","INDEX_NAME = os.getenv(\"INDEX_NAME\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## 1. Setup Langchain Components\n","\n","We will use Index indexed in [this notebook](1.0.0-han-langchain-indexing.ipynb) for our Q&A bot. "]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["llm = OpenAI()\n","embeddings = OpenAIEmbeddings()\n","vectorstore = Redis.from_existing_index(\n","    redis_url=REDIS_URL,\n","    index_name='chat_index',\n","    embedding=embeddings,\n",")"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["prompt_template = \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, say that you don't know, don't try to make up an answer.\n","\n","This should be in the following format:\n","\n","Question: [question here]\n","Answer: [answer here]\n","\n","Begin!\n","\n","Context:\n","---------\n","{context}\n","---------\n","Question: {question}\n","Answer:\"\"\""]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["prompt = PromptTemplate(\n","    template=prompt_template,\n","    input_variables=[\"context\", \"question\"]\n",")"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["chain = RetrievalQA.from_chain_type(\n","    llm=llm,\n","    chain_type=\"stuff\",\n","    retriever=vectorstore.as_retriever(),\n","    return_source_documents=True,\n","    chain_type_kwargs={\"prompt\": prompt}\n",")"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"text/plain":["{'query': 'What is the best way to train models for tabular data?',\n"," 'result': ' It depends on the dataset size and type. Generally, boosted decision trees (XGBoost, CatBoost, or LightGBM) are faster to train and on par with neural networks. However, it is possible to get better results with neural networks if the hyperparameter ranges are carefully chosen and the data is transformed to the model correctly.',\n"," 'source_documents': [Document(page_content='U01HNA2UH60: Is anyone here doing tabular deep learning?U01CTELE17D: We do neural nets, but usually trees wins on our leader boards.U01HNA2UH60: hmm that’s interesting. i’m wondering if the scale of data is a factor?U01CTELE17D: Possibly, but with smart sampling and very limited hyper parameter tuning you can get very accurate model, why bother with neural nets in the first place? where in order to get similar or slightly worse results requires 10x more time and resources.', metadata={'channel_name': 'mlops-questions-answered', 'thread_id': '2021-11-05 21:54:54.2653 UTC'}),\n","  Document(page_content=\"U015BH45ZK6: What's the evidence (blogs, articles) that DL don't work (or not better than other techniques) on tabular data? I'd like to do a review to get to the bottom of this.U029R05NZ4H: i’m not familiar with the literature, but a quick search reveals this recent survey paper <https://arxiv.org/pdf/2110.01889.pdf> with <https://github.com/kathrinse/TabSurvey|its own repo> which seems to be highly relevant\\n\\n&gt; Our results indicate that algorithms based on gradient-boosted tree ensembles still outperform the deep learning models. To the best of our knowledge, this is the first in-depth look at deep learning approaches for tabular data.U01FCPMHETD: To do a review on this, I would just suggest tweeting that deep learning models are bad on tabular data and that the best model is SVM. Then log off twitter, come back three days after, and you will have all the references you need ;)U015BH45ZK6: Great idea, though I might create an alt account and tweet the exact opposite as wellU0147G90NDA: I don't think it's actually the case. DL works quite well on tabular dataU0147G90NDA: There's a book form Manning about it. I think it's called deep learning on tabular data or something like thatU0147G90NDA: <https://datatalks.club/books/20210118-deep-learning-structured-data.html|https://datatalks.club/books/20210118-deep-learning-structured-data.html>\\n\\nHere you go. Check the questionsU01N8ERHH9T: There's a paper from Airbnb on how it took them 2 years of development to figure out how to get better results from DL than xgboost for their search ranking algorithm. It doesn't suggest that DL can't improve results on tabular data, but rather that there were a lot of things to learn and adapt before they figured out how to take advantage of the algorithms and transform their data to them. There are a lot more trainings, tutorials, and advice now that wasn't as prevalent back then, but I think the point remains that you can't just drop in data and get decent results like you can with GBT models. \\n<https://arxiv.org/abs/1810.09591|https://arxiv.org/abs/1810.09591>U016SQ2GM6U: Here is a nice paper:  <https://arxiv.org/abs/2106.03253>U019ABXBYET: This one was at the top of the PTK mailing list recently:\\n\\n<https://arxiv.org/pdf/2110.01889.pdf|https://arxiv.org/pdf/2110.01889.pdf>U03AU56K2JV: Without jumping in myself, the cardinality of features is important. High cardinality provides opportunities for using embeddings in your DL architecture which has shown to outperform traditional machine learning models (e.g. random forest). Reference: <https://www.fast.ai/2018/04/29/categorical-embeddings/>U01G8F6E38T: DL models are better in map out high dimensional smooth surfaces. \\n\\nGBDTs are better in finding out discrete spikes in data, which just happen to be what tabular data is. U01G8F6E38T: Couple years ago there were a few papers trying to demonstrate NN is better than XGboost.\\n\\nBy totally fucking up the hyperparam ranges. \\n\\nJust so they can claim sota. U015BH45ZK6: Than\", metadata={'channel_name': 'discussions', 'thread_id': '2022-05-16 08:55:05.286179 UTC'}),\n","  Document(page_content='U012YQULW4X: the model depends a lot on the data too. we use non deep learning mostly for tabular problemsU022KRHMWEB: Other than Reinforcement learning I don’t see many other alternatives for ML than deep learning NN. But then I might be missing some data analytics work that people call MLU012YQULW4X: • for tabular data, boosted trees are often on par with neural networks and faster to train (good for fast iteration). \\n• some people have regulatory requirements and are restricted in their model choice\\n• I also had some use cases where a simple baseline model got 96% accuracy and that was enough for the commercial use case.\\n• I believe time series problems also work quite well without NN. The popular library prophet developed by facebook is using a combination of a growth function, a seasonality term and a holiday term (nonlinear models, but not NN)U01G1V9K430: I second Lina’s points. i’ve definitely done projects where we’ve deployed GBT models for simple rec sys tasks, manually tuning features.U024SQLAZ38: In my experience, for tabular data, NN are actually normally a bit *less* performant than boosted decision trees (xgboost, catboost or lightgbm) and require quite a bit more work and hardware. Of course, not a general rule, and it depends also a lot on the dataset size and type. This experience of mine is echoed in this blog post I recently read: <https://towardsdatascience.com/the-unreasonable-ineffectiveness-of-deep-learning-on-tabular-data-fd784ea29c33> . However, I did have some success especially with this library: <https://github.com/jrzaurin/pytorch-widedeep> which also allow you to mix tabular data with other modes (images, text...)U02TCG0MU2J: For time series data, I’ve found some NN models to work well from the darts library', metadata={'channel_name': 'mlops-questions-answered', 'thread_id': '2022-01-07 17:38:15.0445 UTC'}),\n","  Document(page_content='U01KPQ38VGS: Hi everyone!\\n\\nWhile training tabular models:\\n• Do you prepare your dataset from scratch from a data warehouse (or other sources)? :one: \\n• Or do you rely on previous predictions (logs of feature vectors) of your model? :two: \\n• Both :three: \\n• Other? Discuss in the :thread: U01KPQ38VGS: I will share my experience in chronological order:\\n\\nContext: Catboost classification model with real-time inference.\\n\\n1. Initially started with SQL on the warehouse, until we realized we had leakage and performance in train and serve did not match.\\n2. We started logging predictions and started training on that after we had enough data. Model performance metrics got better and became consistent with one another. Although this made it *harder* to add new features.U01KPQ38VGS: For 2, how did you solve the adding new features problem?U018RV7QPAA: Isn\\'t 2 just another way of using an offline Feature Store?U01KPQ38VGS: In both cases, the requesting client is calculating the data from scratch and passing it.U01MSDC49QR: I\\'m going to agree with Ariel here. ETL to ship these client-generated feature vectors to offline storage that is curated into a feature store that can be used to train models. Serving (I\\'m assuming you\\'re doing edge deployment here?) should also capture the predictions and utilization aspects of the attribution of the prediction in order to inform how well the solution is working. This would also go to an offline feature store for retraining and solution health reporting.U01KPQ38VGS: :thinking_face:U01KPQ38VGS: <@U01MSDC49QR>, what do you mean by “utilization aspects of the attribution of the prediction”?U01MSDC49QR: attribution modeling in general... \"how do you measure if someone is doing something worthwhile with what your solution is providing?\" the general model / solution health measurement metricU01MSDC49QR: \"How much money is this making us?\"\\n\"How much do our users use this?\"\\n\"How much time does this save people?\"\\n\"Did someone use the prediction or not?\"U01MSDC49QR: typically collected long after the prediction is generatedU01KPQ38VGS: any other ways to do that other than A/B testing / randomized controlled trial?U01KPQ38VGS: asking to learn ^U01MSDC49QR: There are many ways to skin this cat, but what I typically ask customers at the outset of the project is a rather simple question, \"Can I talk to the person who is funding this project?\". Right after they\\'re in the room, I ask them an additional simple question. \"Why are you paying for this to be built?\". In the span of a few minutes, they\\'ll usually give up the goods on what aspect of the business operations is being targeted here.\\nCould be revenue (that\\'s covered by AB testing with appropriate cohort design in sub-group stratification).\\nCould be engagement of customers (that\\'s a bit trickier - you want to do analytics on time-on-app / number-of-times-logging-in / general browsing behavior) This involves building ETL pipelines that collect this data and can be merged to the AB test', metadata={'channel_name': 'mlops-questions-answered', 'thread_id': '2021-05-27 15:17:59.3499 UTC'})]}"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["question = \"What is the best way to train models for tabular data?\"\n","chain({'query': question})"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"data":{"text/plain":["' It depends on the data, but it is often suggested that gradient-boosted tree ensembles still outperform deep learning models, and some have found success using a library called pytorch-widedeep. For time series data, some NN models have been seen to work well from the darts library.'"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["chain({'query': question})['result']"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## 2. Answer Generation"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>question</th>\n","      <th>answer</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Has anyone used Erlang or Elixir in production...</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Is Object Oriented Programming (OOP) terrible ...</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>How do you track inferences over time for ML o...</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Is there a blog or repo with code for a simple...</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>What are some best practices or open source fr...</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                            question  answer\n","0  Has anyone used Erlang or Elixir in production...     NaN\n","1  Is Object Oriented Programming (OOP) terrible ...     NaN\n","2  How do you track inferences over time for ML o...     NaN\n","3  Is there a blog or repo with code for a simple...     NaN\n","4  What are some best practices or open source fr...     NaN"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["df = pd.read_csv('../data/questions_list.csv')\n","df.head()"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["def qa(question:str):\n","    return chain({'query': question})['result']\n","\n","df['answer'] = df['question'].apply(qa)\n","df.to_csv('../data/result_list.csv')"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyM+PK0O8A9lJRy7IacgueMf","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"}},"nbformat":4,"nbformat_minor":0}
